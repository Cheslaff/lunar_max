<h1  align="center"  id="title">LUNA-R MAx</h1>

  

  

<a  href="https://lunarml.tilda.ws/"><p  align="center"><img  src="https://i.ibb.co/tQ9JDTs/Removal-633.png"  alt="LUNA-R MAX"  width=15%></p></a>

  

  

**<p id="description"  align='center'>LUNA-R ML Framework improved.</p>**

  

  

<p  id="description"  align='center'>Made by enthusiast for enthusiasts.</p><br>

  

<p  align='center'>Story:</p><br>

  

<p  align='center'>LUNA-R was simple ML framework like Sklearn</p>

  

<p  align='center'>Project was frozen, developer was banned...</p>

  

<p  align='center'>Now It's back for improvements</p>

  

<p  id="description"  align='center'><h2  align='center'>LUNA-R MAx</h2></p>

  

  

___

  

  

<p  align='center'>Updates:</p>

  

  

<p  align='center'> 16.06.24 Developer is free from exams! LUNA-R Kernel commited and everything is ready for improvement!</p>

  

  

___

  

  

<h3  align="center">Deep Learning Era...<h3>

  

  

<p  align="center">LUNA_R MAX 0.02 is out!</p><br>

  

<p  align="center">Introducing...</p><br>

  

  

<h1  align="center">RetroGrad!</h1>

<p  align="center"><img  src="https://i.ibb.co/zStvD6d/retrograd-removebg.png" width=20%></p>

  

<p  align="center">Inspired with *AutoGrad* from **PyTorch** and *MicroGrad* from **Andrej Karpathy** (thanks sir!)<p><br>

  

<p  align="center">RetroGrad makes Neural Network building process seamlessly intuitive, simple, and scalable!</p><br>

  

<h2  align="center">LUNA-R MAX 0.02 Introduces RetroGrad 0.01</h2>

  

<p  align="center">And...</p>

  

  

<h2  align="center">MLP Class for building Multi-Layer Perceptrons!</h2>